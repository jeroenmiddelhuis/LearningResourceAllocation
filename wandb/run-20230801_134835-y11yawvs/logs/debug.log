2023-08-01 13:48:35,017 INFO    MainThread:5680 [wandb_setup.py:_flush():76] Current SDK version is 0.15.7
2023-08-01 13:48:35,017 INFO    MainThread:5680 [wandb_setup.py:_flush():76] Configure stats pid to 5680
2023-08-01 13:48:35,018 INFO    MainThread:5680 [wandb_setup.py:_flush():76] Loading settings from C:\Users\jeroe\.config\wandb\settings
2023-08-01 13:48:35,018 INFO    MainThread:5680 [wandb_setup.py:_flush():76] Loading settings from C:\Users\jeroe\OneDrive - TU Eindhoven\Documents\Github\LearningResourceAllocation_Interval\LearningResourceAllocation\wandb\settings
2023-08-01 13:48:35,018 INFO    MainThread:5680 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2023-08-01 13:48:35,018 INFO    MainThread:5680 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-08-01 13:48:35,018 INFO    MainThread:5680 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'scenarios\\train_DRL.py', 'program': 'c:\\Users\\jeroe\\OneDrive - TU Eindhoven\\Documents\\Github\\LearningResourceAllocation_Interval\\LearningResourceAllocation\\scenarios\\train_DRL.py'}
2023-08-01 13:48:35,018 INFO    MainThread:5680 [wandb_init.py:_log_setup():507] Logging user logs to C:\Users\jeroe\OneDrive - TU Eindhoven\Documents\Github\LearningResourceAllocation_Interval\LearningResourceAllocation\wandb\run-20230801_134835-y11yawvs\logs\debug.log
2023-08-01 13:48:35,018 INFO    MainThread:5680 [wandb_init.py:_log_setup():508] Logging internal logs to C:\Users\jeroe\OneDrive - TU Eindhoven\Documents\Github\LearningResourceAllocation_Interval\LearningResourceAllocation\wandb\run-20230801_134835-y11yawvs\logs\debug-internal.log
2023-08-01 13:48:35,018 INFO    MainThread:5680 [wandb_init.py:init():547] calling init triggers
2023-08-01 13:48:35,018 INFO    MainThread:5680 [wandb_init.py:init():554] wandb.init called with sweep_config: {}
config: {'policy_type': 'MaskableActorCriticPolicy', 'total_timesteps': 1000000, 'env_name': 'complete'}
2023-08-01 13:48:35,019 INFO    MainThread:5680 [wandb_init.py:init():596] starting backend
2023-08-01 13:48:35,019 INFO    MainThread:5680 [wandb_init.py:init():600] setting up manager
2023-08-01 13:48:35,021 INFO    MainThread:5680 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=spawn, using: spawn
2023-08-01 13:48:35,022 INFO    MainThread:5680 [wandb_init.py:init():606] backend started and connected
2023-08-01 13:48:35,027 INFO    MainThread:5680 [wandb_init.py:init():697] updated telemetry
2023-08-01 13:48:35,056 INFO    MainThread:5680 [wandb_init.py:init():730] communicating run to backend with 60.0 second timeout
2023-08-01 13:48:35,631 INFO    MainThread:5680 [wandb_run.py:_on_init():2174] communicating current version
2023-08-01 13:48:35,939 INFO    MainThread:5680 [wandb_run.py:_on_init():2183] got version response 
2023-08-01 13:48:35,939 INFO    MainThread:5680 [wandb_init.py:init():781] starting run threads in backend
2023-08-01 13:48:40,135 INFO    MainThread:5680 [wandb_run.py:_console_start():2153] atexit reg
2023-08-01 13:48:40,135 INFO    MainThread:5680 [wandb_run.py:_redirect():2008] redirect: wrap_raw
2023-08-01 13:48:40,135 INFO    MainThread:5680 [wandb_run.py:_redirect():2073] Wrapping output streams.
2023-08-01 13:48:40,135 INFO    MainThread:5680 [wandb_run.py:_redirect():2098] Redirects installed.
2023-08-01 13:48:40,136 INFO    MainThread:5680 [wandb_init.py:init():822] run started, returning control to user process
2023-08-01 13:48:40,142 INFO    MainThread:5680 [wandb_run.py:_tensorboard_callback():1428] tensorboard callback: ./scenarios/tmp/complete_1000000_0.01/, True
2023-08-01 13:48:40,157 INFO    MainThread:5680 [wandb_run.py:_config_callback():1282] config_cb None None {'algo': 'MaskablePPO', 'policy_class': "<class 'sb3_contrib.common.maskable.policies.MaskableActorCriticPolicy'>", 'device': 'cpu', 'verbose': 1, 'policy_kwargs': '{}', 'num_timesteps': 0, '_total_timesteps': 1000000, '_num_timesteps_at_start': 0, 'seed': 'None', 'action_noise': 'None', 'start_time': 1690890520143624900, 'learning_rate': 0.0001, 'tensorboard_log': 'None', '_last_obs': '[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]', '_last_episode_starts': '[ True]', '_last_original_obs': 'None', '_episode_num': 0, 'use_sde': 'False', 'sde_sample_freq': -1, '_current_progress_remaining': 1.0, '_stats_window_size': 100, 'ep_info_buffer': 'deque([], maxlen=100)', 'ep_success_buffer': 'deque([], maxlen=100)', '_n_updates': 0, '_custom_logger': 'True', 'env': '<stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x00000200373A6F10>', '_vec_normalize_env': 'None', 'observation_space': 'Box(0.0, [1.00000000e+000 1.00000000e+000 1.00000000e+000 1.00000000e+000\n 1.00000000e+000 1.00000000e+000 1.00000000e+000 1.00000000e+000\n 1.00000000e+000 1.00000000e+000 1.00000000e+000 1.00000000e+000\n 1.30000000e+001 1.30000000e+001 1.30000000e+001 1.30000000e+001\n 1.30000000e+001 1.30000000e+001 1.30000000e+001 1.30000000e+001\n 1.30000000e+001 1.30000000e+001 1.30000000e+001 1.30000000e+001\n 1.00000000e+000 1.00000000e+000 1.00000000e+000 1.00000000e+000\n 1.00000000e+000 1.00000000e+000 1.00000000e+000 1.00000000e+000\n 1.00000000e+000 1.00000000e+000 1.00000000e+000 1.00000000e+000\n 1.00000000e+000 1.79769313e+308], (38,), float64)', 'action_space': 'Discrete(25)', 'n_envs': 1, 'n_steps': 100000, 'gamma': 1, 'gae_lambda': 0.95, 'ent_coef': 0.0, 'vf_coef': 0.5, 'max_grad_norm': 0.5, 'batch_size': 64, 'n_epochs': 10, 'clip_range': '<function constant_fn.<locals>.func at 0x0000020039E59F80>', 'clip_range_vf': 'None', 'normalize_advantage': 'True', 'target_kl': 'None', 'lr_schedule': '<function constant_fn.<locals>.func at 0x0000020039E5A5C0>', 'policy': 'MaskableActorCriticPolicy(\n  (features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (pi_features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (vf_features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (mlp_extractor): MlpExtractor(\n    (policy_net): Sequential(\n      (0): Linear(in_features=38, out_features=64, bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=64, out_features=64, bias=True)\n      (3): Tanh()\n    )\n    (value_net): Sequential(\n      (0): Linear(in_features=38, out_features=64, bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=64, out_features=64, bias=True)\n      (3): Tanh()\n    )\n  )\n  (action_net): Linear(in_features=64, out_features=25, bias=True)\n  (value_net): Linear(in_features=64, out_features=1, bias=True)\n)', 'rollout_buffer': '<sb3_contrib.common.maskable.buffers.MaskableRolloutBuffer object at 0x0000020039E5E8D0>', '_logger': '<stable_baselines3.common.logger.Logger object at 0x0000020039E5E0D0>'}
2023-08-01 13:53:24,976 WARNING MsgRouterThr:5680 [router.py:message_loop():77] message_loop has been closed
