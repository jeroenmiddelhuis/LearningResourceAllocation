Using cpu device
Wrapping the env in a DummyVecEnv.
Logging to ./scenarios/tmp/complete_3000000_0.01/
-------Resetting environment-------
Nr of postpones: 100/5000
Nr of fake transitions: 4761/5000
[1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 2, 3, 4, 6, 6, 0, 7, 0, 0, 0, 0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4]
Nr of postpones: 150/5000
Nr of fake transitions: 4593/5000
[1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 2, 3, 4, 0, 6, 0, 8, 9, 10, 11, 12, 0.0, 0.0, 0.0, 0.6666666666666666, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6]
Nr of postpones: 148/5000
Nr of fake transitions: 4603/5000
[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 4, 3, 5, 5, 8, 8, 9, 10, 0, 0, 0.0, 0.0, 0.0, 0.45454545454545453, 0.0, 0.09090909090909091, 0.0, 0.0, 0.0, 0.45454545454545453, 0.0, 0.0, 0.0, 11]
Nr of postpones: 155/5000
Nr of fake transitions: 4597/5000
[0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 4, 3, 0, 6, 0, 0, 9, 10, 0, 11, 0.0, 0.0, 0.0, 0.375, 0.5625, 0.0, 0.0, 0.0, 0.0, 0.0625, 0.0, 0.0, 0.0, 16]
Nr of postpones: 136/5000
Nr of fake transitions: 4664/5000
[0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 2, 3, 3, 6, 0, 0, 7, 10, 0, 12, 12, 0.0, 0.043478260869565216, 0.08695652173913043, 0.0, 0.5652173913043478, 0.0, 0.0, 0.0, 0.0, 0.13043478260869565, 0.0, 0.13043478260869565, 0.043478260869565216, 23]
Nr of postpones: 167/5000
Nr of fake transitions: 4569/5000
[1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 2, 3, 3, 5, 6, 0, 0, 9, 0, 11, 12, 0.0, 0.0, 0.0, 0.125, 0.5, 0.041666666666666664, 0.20833333333333334, 0.0, 0.0, 0.08333333333333333, 0.0, 0.0, 0.041666666666666664, 24]
Uncompleted cases: 31
Resource utilisation: [('Resource 1', 0.6847656227400928), ('Resource 2', 0.7125833879080211), ('Resource 3', 0.9414807329370821), ('Resource 4', 0.9235877162737688), ('Resource 5', 0.6488763231197314), ('Resource 6', 0.7570751729217163), ('Resource 7', 0.6025555208361537), ('Resource 8', 0.6812861122344159), ('Resource 9', 0.6468589298430935), ('Resource 10', 0.22456016786585725), ('Resource 11', 0.6287038924262446), ('Resource 12', 0.6223761523299582)]
Total reward: -5856.839355307393. Total CT: 5856.839355308097
Mean cycle time: 41.24534757259223. Standard deviation: 16.734811605839496
mean 0.010000333333329071 min 0.009999999999990905 max 0.02
-------Resetting environment-------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 3e+04     |
|    ep_rew_mean     | -5.86e+03 |
| time/              |           |
|    fps             | 985       |
|    iterations      | 1         |
|    time_elapsed    | 30        |
|    total_timesteps | 30000     |
----------------------------------
Nr of postpones: 90/5000
Nr of fake transitions: 4784/5000
[0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 5, 6, 0, 0, 0, 0, 0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1]
Nr of postpones: 162/5000
Nr of fake transitions: 4609/5000
[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 3, 4, 5, 0, 7, 7, 10, 10, 0, 0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.0, 0.0, 12]
Nr of postpones: 198/5000
Nr of fake transitions: 4546/5000
[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 2, 3, 3, 5, 6, 0, 8, 10, 10, 12, 11, 0.0, 0.0, 0.0, 0.36363636363636365, 0.18181818181818182, 0.18181818181818182, 0.2727272727272727, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11]
Nr of postpones: 197/5000
Nr of fake transitions: 4552/5000
[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 2, 1, 3, 3, 5, 5, 8, 7, 0, 0, 12, 12, 0.0, 0.3333333333333333, 0.041666666666666664, 0.0, 0.041666666666666664, 0.125, 0.08333333333333333, 0.0, 0.041666666666666664, 0.0, 0.0, 0.08333333333333333, 0.25, 24]
Nr of postpones: 188/5000
Nr of fake transitions: 4512/5000
[1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 3, 4, 6, 6, 0, 7, 9, 0, 12, 11, 0.0, 0.0, 0.0, 0.7058823529411765, 0.17647058823529413, 0.0, 0.0, 0.0, 0.0, 0.11764705882352941, 0.0, 0.0, 0.0, 17]
Nr of postpones: 179/5000
Nr of fake transitions: 4560/5000
[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 2, 2, 4, 3, 5, 5, 7, 8, 0, 0, 11, 12, 0.0, 0.08333333333333333, 0.16666666666666666, 0.20833333333333334, 0.25, 0.041666666666666664, 0.041666666666666664, 0.041666666666666664, 0.125, 0.0, 0.0, 0.041666666666666664, 0.0, 24]
Uncompleted cases: 33
Resource utilisation: [('Resource 1', 0.7359320379639933), ('Resource 2', 0.7698206186804313), ('Resource 3', 0.8556317813657796), ('Resource 4', 0.8837264739044666), ('Resource 5', 0.760718764253435), ('Resource 6', 0.8075413261977332), ('Resource 7', 0.6900253522650309), ('Resource 8', 0.6561407492653479), ('Resource 9', 0.6416377916324639), ('Resource 10', 0.29099953905970277), ('Resource 11', 0.6959927592158247), ('Resource 12', 0.7033652326878042)]
Total reward: -6043.468453215183. Total CT: 6043.468453214817
Mean cycle time: 40.022969888839846. Standard deviation: 15.921672780028814
mean 0.010000333333329071 min 0.009999999999990905 max 0.02
-------Resetting environment-------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 3e+04         |
|    ep_rew_mean          | -5.95e+03     |
| time/                   |               |
|    fps                  | 695           |
|    iterations           | 2             |
|    time_elapsed         | 86            |
|    total_timesteps      | 60000         |
| train/                  |               |
|    approx_kl            | 0.00024480117 |
|    clip_fraction        | 0.0118        |
|    clip_range           | 0.1           |
|    entropy_loss         | -0.0695       |
|    explained_variance   | 0.00101       |
|    learning_rate        | 0.0001        |
|    loss                 | 0.00788       |
|    n_updates            | 10            |
|    policy_gradient_loss | -0.00103      |
|    value_loss           | 0.305         |
-------------------------------------------
Nr of postpones: 123/5000
Nr of fake transitions: 4682/5000
[1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 3, 3, 5, 6, 8, 0, 9, 0, 11, 12, 0.0, 0.0, 0.0, 0.5, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2]
Nr of postpones: 132/5000
Nr of fake transitions: 4655/5000
[1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 4, 3, 6, 0, 7, 7, 9, 0, 11, 11, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2]
Nr of postpones: 103/5000
Nr of fake transitions: 4709/5000
[1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 2, 4, 4, 6, 5, 7, 7, 0, 0, 11, 11, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 3]
Nr of postpones: 149/5000
Nr of fake transitions: 4633/5000
[0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 2, 2, 3, 4, 5, 6, 0, 7, 10, 0, 11, 0, 0.0, 0.2222222222222222, 0.0, 0.1111111111111111, 0.1111111111111111, 0.2222222222222222, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9]
Nr of postpones: 151/5000
Nr of fake transitions: 4590/5000
[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 4, 5, 6, 8, 7, 9, 10, 12, 12, 0.0, 0.0, 0.0, 0.17647058823529413, 0.0, 0.35294117647058826, 0.11764705882352941, 0.058823529411764705, 0.0, 0.17647058823529413, 0.11764705882352941, 0.0, 0.0, 17]
Nr of postpones: 136/5000
Nr of fake transitions: 4608/5000
[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 3, 3, 5, 5, 7, 7, 9, 0, 12, 11, 0.0, 0.07692307692307693, 0.15384615384615385, 0.0, 0.0, 0.15384615384615385, 0.0, 0.15384615384615385, 0.0, 0.15384615384615385, 0.0, 0.07692307692307693, 0.23076923076923078, 13]
Uncompleted cases: 22
Resource utilisation: [('Resource 1', 0.7227723242482713), ('Resource 2', 0.7247952820272662), ('Resource 3', 0.8086202235011858), ('Resource 4', 0.8373842160682863), ('Resource 5', 0.7126521189803813), ('Resource 6', 0.7872205295735324), ('Resource 7', 0.5988352431348918), ('Resource 8', 0.6702250058787743), ('Resource 9', 0.6653962797095347), ('Resource 10', 0.31596072904826794), ('Resource 11', 0.6473318040501153), ('Resource 12', 0.6303212598033514)]
Total reward: -4568.595310712439. Total CT: 4568.59531071264
Mean cycle time: 34.61057053570182. Standard deviation: 13.43868088472907
mean 0.010000333333329071 min 0.009999999999990905 max 0.02
-------Resetting environment-------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 3e+04         |
|    ep_rew_mean          | -5.49e+03     |
| time/                   |               |
|    fps                  | 646           |
|    iterations           | 3             |
|    time_elapsed         | 139           |
|    total_timesteps      | 90000         |
| train/                  |               |
|    approx_kl            | 0.00024415308 |
|    clip_fraction        | 0.0108        |
|    clip_range           | 0.1           |
|    entropy_loss         | -0.0777       |
|    explained_variance   | 0.739         |
|    learning_rate        | 0.0001        |
|    loss                 | 0.0233        |
|    n_updates            | 20            |
|    policy_gradient_loss | -0.000892     |
|    value_loss           | 0.327         |
-------------------------------------------
Nr of postpones: 132/5000
Nr of fake transitions: 4702/5000
[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 1, 3, 4, 6, 6, 8, 7, 9, 0, 0, 0, 0.0, 0.2857142857142857, 0.0, 0.42857142857142855, 0.0, 0.0, 0.0, 0.0, 0.07142857142857142, 0.21428571428571427, 0.0, 0.0, 0.0, 14]
Nr of postpones: 227/5000
Nr of fake transitions: 4520/5000
[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 1, 4, 4, 5, 6, 8, 7, 9, 0, 11, 12, 0.0, 0.05263157894736842, 0.10526315789473684, 0.3157894736842105, 0.0, 0.15789473684210525, 0.05263157894736842, 0.0, 0.0, 0.10526315789473684, 0.0, 0.10526315789473684, 0.10526315789473684, 19]
Nr of postpones: 217/5000
Nr of fake transitions: 4514/5000
[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 2, 4, 4, 6, 6, 8, 8, 9, 0, 11, 11, 0.0, 0.0, 0.0, 0.22727272727272727, 0.22727272727272727, 0.09090909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18181818181818182, 0.2727272727272727, 22]
Nr of postpones: 212/5000
Nr of fake transitions: 4500/5000
[0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 3, 4, 5, 5, 0, 0, 9, 0, 12, 11, 0.0, 0.0, 0.0, 0.46153846153846156, 0.0, 0.038461538461538464, 0.07692307692307693, 0.0, 0.0, 0.038461538461538464, 0.0, 0.11538461538461539, 0.2692307692307692, 26]
Nr of postpones: 158/5000
Nr of fake transitions: 4577/5000
[0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 2, 3, 4, 5, 5, 0, 0, 9, 0, 12, 11, 0.0, 0.043478260869565216, 0.0, 0.08695652173913043, 0.5652173913043478, 0.043478260869565216, 0.0, 0.0, 0.0, 0.13043478260869565, 0.0, 0.13043478260869565, 0.0, 23]
Nr of postpones: 212/5000
Nr of fake transitions: 4510/5000
[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 3, 3, 6, 6, 7, 8, 10, 10, 12, 11, 0.0, 0.0, 0.0, 0.2, 0.0, 0.55, 0.05, 0.05, 0.0, 0.0, 0.05, 0.05, 0.05, 20]
Uncompleted cases: 29
Resource utilisation: [('Resource 1', 0.7993767678825735), ('Resource 2', 0.7368011929854189), ('Resource 3', 0.9885469209021361), ('Resource 4', 0.9784391411717522), ('Resource 5', 0.8659026270202429), ('Resource 6', 0.8611679622022195), ('Resource 7', 0.7355570002101296), ('Resource 8', 0.7030315008574473), ('Resource 9', 0.7096563271491914), ('Resource 10', 0.3226911120683742), ('Resource 11', 0.7494598967366468), ('Resource 12', 0.7378683352233575)]
Total reward: -7920.535340057763. Total CT: 7920.53534005827
Mean cycle time: 51.43204766271604. Standard deviation: 14.886214066983927
mean 0.010000333333329071 min 0.009999999999990905 max 0.02
-------Resetting environment-------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 3e+04         |
|    ep_rew_mean          | -6.1e+03      |
| time/                   |               |
|    fps                  | 617           |
|    iterations           | 4             |
|    time_elapsed         | 194           |
|    total_timesteps      | 120000        |
| train/                  |               |
|    approx_kl            | 0.00022653234 |
|    clip_fraction        | 0.0103        |
|    clip_range           | 0.1           |
|    entropy_loss         | -0.0673       |
|    explained_variance   | 0.888         |
|    learning_rate        | 0.0001        |
|    loss                 | 0.0157        |
|    n_updates            | 30            |
|    policy_gradient_loss | -0.0011       |
|    value_loss           | 0.212         |
-------------------------------------------
Nr of postpones: 152/5000
Nr of fake transitions: 4629/5000
[1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 3, 3, 6, 6, 0, 0, 9, 0, 12, 12, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.25, 0.0, 0.0, 0.25, 0.0, 0.25, 0.0, 4]
Nr of postpones: 157/5000
Nr of fake transitions: 4627/5000
[0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 4, 3, 0, 0, 0, 7, 9, 10, 0, 0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 3]
Nr of postpones: 145/5000
Nr of fake transitions: 4631/5000
[0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 2, 0, 3, 3, 5, 0, 0, 7, 9, 0, 0, 12, 0.0, 0.0, 0.0, 0.5, 0.375, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 8]
Nr of postpones: 156/5000
Nr of fake transitions: 4612/5000
[1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 3, 3, 0, 6, 7, 8, 9, 10, 0, 11, 0.0, 0.0, 0.0, 0.0, 0.18181818181818182, 0.0, 0.0, 0.09090909090909091, 0.0, 0.7272727272727273, 0.0, 0.0, 0.0, 11]
Nr of postpones: 163/5000
Nr of fake transitions: 4578/5000
[0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 4, 3, 5, 0, 0, 0, 9, 0, 12, 12, 0.0, 0.05263157894736842, 0.10526315789473684, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3684210526315789, 0.0, 0.3157894736842105, 0.15789473684210525, 19]
Nr of postpones: 186/5000
Nr of fake transitions: 4559/5000
[0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 2, 4, 4, 0, 0, 0, 7, 9, 10, 12, 11, 0.0, 0.2, 0.1, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.0, 0.2, 0.0, 10]
Uncompleted cases: 18
Resource utilisation: [('Resource 1', 0.6539484481715842), ('Resource 2', 0.5936550088481934), ('Resource 3', 0.7834600930582212), ('Resource 4', 0.7717616326148071), ('Resource 5', 0.6982321454610505), ('Resource 6', 0.7587173632571568), ('Resource 7', 0.6704017636356634), ('Resource 8', 0.6414216761594469), ('Resource 9', 0.749779453964575), ('Resource 10', 0.3509978548238814), ('Resource 11', 0.6178194895744075), ('Resource 12', 0.6498370082026083)]
Total reward: -4614.963593770568. Total CT: 4614.963593770797
Mean cycle time: 33.685865647962025. Standard deviation: 16.922732986312536
mean 0.010000333333329071 min 0.009999999999990905 max 0.02
-------Resetting environment-------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3e+04        |
|    ep_rew_mean          | -5.8e+03     |
| time/                   |              |
|    fps                  | 599          |
|    iterations           | 5            |
|    time_elapsed         | 250          |
|    total_timesteps      | 150000       |
| train/                  |              |
|    approx_kl            | 0.0002495229 |
|    clip_fraction        | 0.01         |
|    clip_range           | 0.1          |
|    entropy_loss         | -0.0847      |
|    explained_variance   | 0.923        |
|    learning_rate        | 0.0001       |
|    loss                 | 0.0181       |
|    n_updates            | 40           |
|    policy_gradient_loss | -0.000924    |
|    value_loss           | 0.758        |
------------------------------------------
Nr of postpones: 141/5000
Nr of fake transitions: 4686/5000
[1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 3, 3, 5, 5, 0, 0, 9, 10, 0, 0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3]
Nr of postpones: 130/5000
Nr of fake transitions: 4639/5000
[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 4, 4, 6, 6, 7, 0, 9, 10, 0, 12, 0.0, 0.0, 0.25, 0.25, 0.0, 0.0, 0.25, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 4]
Nr of postpones: 158/5000
Nr of fake transitions: 4600/5000
[0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 2, 0, 3, 3, 6, 5, 7, 0, 9, 0, 11, 0, 0.0, 0.0, 0.0, 0.2222222222222222, 0.1111111111111111, 0.3333333333333333, 0.2222222222222222, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1111111111111111, 9]
Nr of postpones: 194/5000
Nr of fake transitions: 4554/5000
[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 1, 3, 3, 5, 6, 8, 8, 9, 0, 0, 0, 0.0, 0.0, 0.0, 0.05263157894736842, 0.15789473684210525, 0.3684210526315789, 0.10526315789473684, 0.0, 0.15789473684210525, 0.15789473684210525, 0.0, 0.0, 0.0, 19]
Nr of postpones: 180/5000
Nr of fake transitions: 4564/5000
[0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 3, 4, 6, 6, 8, 8, 9, 0, 0, 11, 0.0, 0.0, 0.0, 0.2, 0.05, 0.15, 0.05, 0.45, 0.05, 0.05, 0.0, 0.0, 0.0, 20]
Traceback (most recent call last):
  File "c:\Users\s144763\OneDrive - TU Eindhoven\Documents\Github\LearningResourceAllocation_Interval\LearningResourceAllocation\scenarios\train_DRL.py", line 98, in <module>
    model.learn(total_timesteps=int(time_steps), callback=WandbCallback())
  File "C:\Users\s144763\Anaconda3\envs\drl\Lib\site-packages\sb3_contrib\ppo_mask\ppo_mask.py", line 526, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, self.n_steps, use_masking)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\s144763\Anaconda3\envs\drl\Lib\site-packages\sb3_contrib\ppo_mask\ppo_mask.py", line 303, in collect_rollouts
    actions, values, log_probs = self.policy(obs_tensor, action_masks=action_masks)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\s144763\Anaconda3\envs\drl\Lib\site-packages\torch\nn\modules\module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\s144763\Anaconda3\envs\drl\Lib\site-packages\sb3_contrib\common\maskable\policies.py", line 130, in forward
    latent_pi, latent_vf = self.mlp_extractor(features)
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\s144763\Anaconda3\envs\drl\Lib\site-packages\torch\nn\modules\module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\s144763\Anaconda3\envs\drl\Lib\site-packages\stable_baselines3\common\torch_layers.py", line 222, in forward
    return self.forward_actor(features), self.forward_critic(features)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\s144763\Anaconda3\envs\drl\Lib\site-packages\stable_baselines3\common\torch_layers.py", line 225, in forward_actor
    return self.policy_net(features)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\s144763\Anaconda3\envs\drl\Lib\site-packages\torch\nn\modules\module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\s144763\Anaconda3\envs\drl\Lib\site-packages\torch\nn\modules\container.py", line 217, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "C:\Users\s144763\Anaconda3\envs\drl\Lib\site-packages\torch\nn\modules\module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\s144763\Anaconda3\envs\drl\Lib\site-packages\torch\nn\modules\linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt